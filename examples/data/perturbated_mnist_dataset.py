from __future__ import annotations

# Annotations
__author__ = "Sebastian Baum"
__maintainer__ = "Sebastian Baum"
__version__ = "1.0.0"
__status__ = "Prototype"

# For annotation
from typing import Tuple

# Imports
import torch
from torch.utils.data import Dataset
import torchvision.datasets as datasets

import warnings
import glob
import os


class PerturbatedMnist(Dataset):
    """
    Dataset that contains the mnist dataset and on top perturbated mnist data generated by alva.
    """

    def __init__(
        self,
        root: str,
        split: str,
        transform=None,
        only_pert=False,
        mnist_folder="MNIST",
        pert_mnist_folder="PERT_MNIST",
    ) -> PerturbatedMnist:
        """
        Initializes PerturbatedMnist Dataset.

        :param root: The root directory of the dataset. It is assumed that in this directory is orign_folder and pert_folder.
        :param split: The split of the training. Possible values are test, training and validation.
        :param transform: The transform to apply to the dataset.
        :param only_pert: Indicates if only the perturbated data will be loaded. Default: False.
        :param mnist_folder: The folder that contains the MNIST data. Default: "MNIST".
        :param pert_mnist_folder: The folder that containts the perturbated MNIST data. Default: "PERT_MNIST".

        :return: The isntance of the class.
        """
        self.__pt_file_pattern = "*.pt"
        self.__root_dir = root
        self.__split = split
        self.__transform = transform
        self.__perturbatedPercentage = 0.0
        self.__only_pert = only_pert

        # Get folder extension
        split_folders = ("test", "training")
        if split not in split_folders:
            raise ValueError(
                f'Invalid Split. Please select one of following splits: {", ".join(split_folders)}'
            )

        # Get paths
        self.__origin_dir = os.path.join(root, mnist_folder)
        self.__pert_dir = os.path.join(root, pert_mnist_folder)

        # Check paths
        if not os.path.exists(self.__origin_dir) and not self.__only_pert:
            raise FileNotFoundError(
                f"MNIST data is not in '{self.__origin_dir}' found. Please download it first."
            )
        # If no path created, create
        if not os.path.exists(self.__pert_dir):
            os.mkdir(self.__pert_dir)

        # Get the data
        self.data, self.targets = None, None
        self.origin_data, self.origin_target = None, None
        self.pert_data, self.pert_label = None, None
        self.load_data()

    def load_data(self) -> None:
        """
        Checks the folder and reloads data. If new runs occured, also includes them into data.

        :return: None.
        """
        (
            self.origin_data,
            self.origin_target,
            self.pert_data,
            self.pert_label,
        ) = self.__get_data()

        # Combine data to one tensor
        self.data = torch.cat((self.origin_data, self.pert_data))
        self.targets = torch.cat((self.origin_target, self.pert_label))

        print(self.data.shape, self.targets.shape)
        # Calculate information
        n_data = len(self.origin_data)
        n_pert_data = len(self.pert_data)

        if n_data + n_pert_data > 0:
            self.__perturbatedPercentage = (
                100 * float(len(self.pert_data)) / (n_pert_data + n_data)
            )
        else:
            self.__perturbatedPercentage = 0.0

    def get_perturbated_percentage(self) -> float:
        return self.__perturbatedPercentage

    def __get_data(
        self,
    ) -> Tuple(torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):
        """
        Gets the data from the directoy.

        :return: The data in form of: mnist data tensor, mnist label tensor, perturbated mnist data tensor, perturbated mnist label tensor.
        """
        # Declare variables
        origin_data, origin_labels = torch.Tensor(), torch.Tensor()
        pert_data, pert_target = torch.Tensor(), torch.Tensor()

        # Get original data
        # origin_torch_path = f"{self.__origin_dir}/{self.__split}.pt"
        # if not self.__only_pert:
        #    if os.path.exists(origin_torch_path):
        #         origin_data, origin_labels = torch.load(origin_torch_path)
        #    else:
        #        warnings.warn(
        #            f"No original data file {origin_torch_path} found. The original mnist dataset is not included."
        #        )
        print(self.__origin_dir)
        train_data = datasets.MNIST(
            self.__origin_dir, True if self.__split == "training" else False, None
        )
        self.origin_data = train_data.data
        self.origin_target = train_data.targets

        print(self.origin_data.shape, self.origin_target.shape)

        # Get the data from runs
        pert_data_files = glob.glob(
            f"{self.__pert_dir}/*{self.__split}{self.__pt_file_pattern}"
        )
        pert_tensor = [torch.load(file) for file in pert_data_files]

        if len(pert_tensor) > 0:
            pert_data, pert_target = list(zip(*pert_tensor))
            pert_data, pert_target = torch.cat(pert_data), torch.cat(pert_target)

        return origin_data, origin_labels, pert_data, pert_target

    def __len__(self) -> int:
        """
        Returns the length of the dataset.

        :return: length of dataset.
        """
        return len(self.data)

    def __getitem__(self, idx) -> Tuple(torch.Tensor, torch.Tensor):
        """
        Returns a tuple with data and label with provided index.

        :param idx: The index to get the data.

        :return: Tuple of x and y as tensor.
        """
        if torch.is_tensor(idx):
            idx = idx.tolist()

        data, label = self.data[idx], self.targets[idx]

        # Apply transformation if provided.
        if self.__transform != None:
            data = self.__transform(data.numpy())

        return data, label.long()

    def __str__(self) -> str:
        """
        Override of string method and display information.
        """
        return (
            "Perturbated MNIST Dataset\n"
            + f"    Number of datapoints: {self.__len__()}\n"
            + f"    Root location: {self.__root_dir}\n"
            + f"    Split: {self.__split}\n"
            + "    StandardTransform:\n"
            + f"Transform: {self.__transform.__repr__()}"
        )
