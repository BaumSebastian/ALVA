{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/venvs/s_baum/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "from config import load_config, add_config_entry\n",
    "\n",
    "# Own Implementations\n",
    "from pipeline import generate_samples_with_iterative_epsilons_by_config\n",
    "from classifiers.mnist import LeNet5\n",
    "from datasets import mnist\n",
    "from utils import set_random_seed\n",
    "\n",
    "# Documentation\n",
    "from plot import generate_plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: convergenz_training_100\n",
      "n_conv_epochs: 100\n",
      "save_paths:\n",
      "  origin: ${dataset.path}/origin\n",
      "  models: ${dataset.path}/models\n",
      "  runs: ${dataset.path}/runs\n",
      "  losses: ${dataset.path}/losses\n",
      "  epsilons: ${dataset.path}/epsilons\n",
      "  general: ${dataset.path}/general\n",
      "  pictures: ${dataset.path}/pictures\n",
      "general:\n",
      "  standard:\n",
      "    random_seed: 0\n",
      "  device: cuda\n",
      "dataset:\n",
      "  general:\n",
      "    offset: datasets\n",
      "  shape:\n",
      "    C: 1\n",
      "    B: 28\n",
      "    H: 28\n",
      "  classes:\n",
      "  - 0\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "  - 6\n",
      "  - 7\n",
      "  - 8\n",
      "  - 9\n",
      "  name: pert_mnist\n",
      "  path: ${dataset.general.offset}/PERT_MNIST_100\n",
      "hyperparameter:\n",
      "  N_EPOCHS: 15\n",
      "  BATCH_SIZE: 32\n",
      "  LEARNING_RATE: 0.001\n",
      "models:\n",
      "  generator: generativeModels/gan/mnist_28_cgan_generator2.pth\n",
      "  discriminator: generativeModels/gan/mnist_28_cgan_discriminator.pth\n",
      "  optimizer: generativeModels/gan/mnist_28_cgan_optimizer.pth\n",
      "  classifier: classifiers/mnist/mnist_28_lenet.pth\n",
      "pipeline:\n",
      "  general:\n",
      "    timeout: 700\n",
      "    n_generated_samples: 70\n",
      "  gradient_type: fgsm\n",
      "  gradient_arguments:\n",
      "    lower_norm: -1\n",
      "    higher_norm: 1\n",
      "    epsilon: 0.2\n",
      "  epsilons: null\n",
      "  return_epsilon: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"conf\", \"convergenz_training_100\")\n",
    "\n",
    "# Set random seed\n",
    "set_random_seed(cfg.general.standard.random_seed)\n",
    "\n",
    "# Check if folders exist and copy original values\n",
    "for directory in cfg.save_paths.values():\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "# Get Device\n",
    "DEVICE = torch.device(cfg.general.device)\n",
    "\n",
    "# Set Hyperparameters\n",
    "BATCH_SIZE = cfg.hyperparameter.BATCH_SIZE\n",
    "LEARNING_RATE = cfg.hyperparameter.LEARNING_RATE\n",
    "N_EPOCHS = cfg.hyperparameter.N_EPOCHS\n",
    "N_EPSILON_EPOCHS = cfg.n_conv_epochs\n",
    "\n",
    "# General information about mnist\n",
    "DATA_DIM = tuple(cfg.dataset.shape.values())\n",
    "CLASSES = cfg.dataset.classes\n",
    "\n",
    "# Load Data\n",
    "original_training_data, _ = mnist.get_dataset(cfg.dataset.general.offset)\n",
    "per_training_data = mnist.PerturbatedMnist(cfg.dataset.path, 'training', transform = mnist.get_standard_transformation())\n",
    "per_test_data = mnist.PerturbatedMnist(cfg.dataset.path, 'test', transform = mnist.get_standard_transformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(cfg):\n",
    "    # Generate samples\n",
    "    _, generator, (z, y, per_z, per_y, epsilons) = generate_samples_with_iterative_epsilons_by_config(cfg)\n",
    "    print(f\"Generated {len(z)} adversarial samples with generator\")\n",
    "    # Save pictures for later.\n",
    "    x, per_x = generator(z).detach().cpu(), generator(per_z).detach().cpu()\n",
    "    return x, y, per_x, per_y, epsilons\n",
    "\n",
    "\n",
    "#def train(train_loader, model, criterion, optimizer, device):\n",
    "#    '''\n",
    "#    Function for the training step of the training loop\n",
    "#    '''\n",
    "#    model.train()\n",
    "#    running_loss = 0\n",
    "#    \n",
    "#    for X, y_true in train_loader:\n",
    "#        optimizer.zero_grad()\n",
    "#        X, y_true = X.to(device), y_true.to(device)\n",
    "#    \n",
    "#        # Forward pass\n",
    "#        y_hat = model(X) \n",
    "#        loss = criterion(y_hat, y_true) \n",
    "#        running_loss += loss.item() * X.size(0)\n",
    "#\n",
    "#        # Backward pass\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#        \n",
    "#    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#    return model, optimizer, epoch_loss\n",
    "#def validate(valid_loader, model, criterion, device):\n",
    "#    '''\n",
    "#    Function for the validation step of the training loop\n",
    "#    '''\n",
    "#    model.eval()\n",
    "#    running_loss = 0\n",
    "#    \n",
    "#    for X, y_true in valid_loader:\n",
    "#    \n",
    "#        X, y_true = X.to(device), y_true.to(device)\n",
    "#\n",
    "#        # Forward pass and record loss\n",
    "#        y_hat = model(X) \n",
    "#        loss = criterion(y_hat, y_true) \n",
    "#        running_loss += loss.item() * X.size(0)\n",
    "#\n",
    "#    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "#        \n",
    "#    return model, epoch_loss\n",
    "# def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "#    '''\n",
    "#    Function defining the entire training loop\n",
    "#    '''\n",
    "#    # set objects for storing metrics\n",
    "#    best_loss = 1e10\n",
    "#    train_losses = []\n",
    "#    valid_losses = []\n",
    "#    train_accuracy = []\n",
    "#    valid_accuracy = []\n",
    "#\n",
    "#    # Train model\n",
    "#    for epoch in range(0, epochs):\n",
    "#\n",
    "#        # training\n",
    "#        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "#        train_losses.append(train_loss)\n",
    "#\n",
    "#        # validation\n",
    "#        with torch.no_grad():\n",
    "#            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "#            valid_losses.append(valid_loss)\n",
    "#\n",
    "#        if epoch % print_every == (print_every - 1):\n",
    "#            \n",
    "#            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "#            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "#            \n",
    "#            train_accuracy.append(train_acc)\n",
    "#            valid_accuracy.append(valid_acc)\n",
    "#            \n",
    "#            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "#                  f'Epoch: {epoch}\\t'\n",
    "#                  f'Train loss: {train_loss:.4f}\\t'\n",
    "#                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "#                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "#                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "#    \n",
    "#    return model, optimizer, (train_losses, valid_losses, train_accuracy, valid_accuracy)\n",
    "#\n",
    "#def get_accuracy(model, data_loader, device):\n",
    "#    '''\n",
    "#    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "#    '''\n",
    "#    \n",
    "#    correct_pred = 0 \n",
    "#    n = 0\n",
    "#    \n",
    "#    with torch.no_grad():\n",
    "#        model.eval()\n",
    "#        for X, y_true in data_loader:\n",
    "#            X, y_true = X.to(device), y_true.to(device)\n",
    "#\n",
    "#            y_hat = model(X)\n",
    "#            predicted_labels = y_hat.max(1, keepdim=True)[1].squeeze()\n",
    "#            n += y_true.size(0)\n",
    "#            correct_pred += (predicted_labels == y_true).float().sum()\n",
    "#\n",
    "#    return correct_pred.float() / n\n",
    "\n",
    "def unnormalize_tensor(t):\n",
    "    return  ((t + 1) * 255).type(torch.uint8)\n",
    "\n",
    "def split_tensor_random(x, y, fraction = 1/6):\n",
    "    if fraction > 1:\n",
    "        raise ValueError(\"Fraction can't be greater than 1\")\n",
    "    \n",
    "    length = len(x)\n",
    "    split = int(length * fraction)\n",
    "    \n",
    "    random_idx = torch.randperm(len(x))\n",
    "    return x[random_idx][:split], y[random_idx][:split], x[random_idx][split:], y[random_idx][split:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "Executing Experiment: #000\n",
      "\n",
      "Perturbated images: 0.0%\n",
      "--------------------------\n",
      "\n",
      "\n",
      "TRAINING\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4c04ea141158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Train the model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTRAINING\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Save the model and load it into the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0e784cc0fba3>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0e784cc0fba3>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/s_baum/classifiers/mnist/lenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/s_baum/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perturbated_percentage = []\n",
    "for epsilon_epoch in range(N_EPSILON_EPOCHS):\n",
    "    # Declare experiment specific variables\n",
    "    run_name = f\"{epsilon_epoch:03}\"\n",
    "    losses_path = f'{cfg.save_paths.losses}/loss_{run_name}.pt'\n",
    "    epsilons_path = f'{cfg.save_paths.epsilons}/epsilons_{run_name}.pt'\n",
    "    model_path = f'{cfg.save_paths.models}/lenet_{run_name}.pth'\n",
    "\n",
    "    # Reload data and create Dataloader\n",
    "    per_training_data.load_data()\n",
    "    per_test_data.load_data()\n",
    "    train_loader = DataLoader(per_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(per_test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    perturbated_percentage.append((per_training_data.get_perturbated_percentage(), per_test_data.get_perturbated_percentage()))\n",
    "\n",
    "    # Start run\n",
    "    print(f'\\n--------------------------')\n",
    "    print(f'Executing Experiment: #{run_name}')\n",
    "    print(f'\\nPerturbated images: {round(per_training_data.get_perturbated_percentage(), 3)}%')\n",
    "    print(f'--------------------------\\n')\n",
    "\n",
    "    # Reinitialize model\n",
    "    model = LeNet5().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model on the dataset\n",
    "    print(\"\\nTRAINING\\n\")\n",
    "    model, optimizer, metrics = training_loop(model, criterion, optimizer, train_loader, test_loader, N_EPOCHS, DEVICE)\n",
    "\n",
    "    # Save the model and load it into the config\n",
    "    torch.save(model, model_path)\n",
    "    cfg.models.classifier = model_path\n",
    "\n",
    "    # Exceut the pipelin to generate samples for every class\n",
    "    per_xs = []\n",
    "    targets = []\n",
    "    all_target_figures = []\n",
    "    epsilons  = []\n",
    "\n",
    "    print(\"\\nGENERATING\\n\")\n",
    "    for target in CLASSES:\n",
    "        add_config_entry(cfg, 'target', target)\n",
    "        print(\"\\nGoing for \" + str(target) + \"\\n\")\n",
    "\n",
    "        # Generating images and storing figures \n",
    "        x, y, per_x, per_y, epsilon = generate_samples(cfg)\n",
    "        figures = generate_plots(x, y, per_x, per_y, cfg.target, original_training_data, DATA_DIM, cfg.dataset.name)\n",
    "\n",
    "        per_xs.append(unnormalize_tensor(per_x))\n",
    "        targets.append(torch.full((1, per_x.shape[0]), target, dtype=int))\n",
    "        all_target_figures.append((target, figures))\n",
    "        epsilons.append((target, epsilon))\n",
    "\n",
    "    # Process data\n",
    "    x_test, y_test, x_train, y_train = split_tensor_random(torch.cat(per_xs).view(-1, 28,28), torch.cat(targets, dim=1).view(-1))\n",
    "\n",
    "    # Save torchs\n",
    "    torch.save(torch.Tensor(metrics), losses_path)\n",
    "    torch.save(epsilons, epsilons_path)\n",
    "    torch.save((x_train, y_train), f'{cfg.save_paths.runs}/{run_name}_training.pt')\n",
    "    torch.save((x_test, y_test), f'{cfg.save_paths.runs}/{run_name}_test.pt')\n",
    "    torch.save(torch.Tensor(perturbated_percentage), cfg.save_paths.general + \"/perturbated_percentage.pt\")\n",
    "    # Save figures\n",
    "    # Save figures\n",
    "    pic_folder = f'{cfg.save_paths.pictures}/{run_name}'\n",
    "    if not os.path.isdir(pic_folder):\n",
    "        os.mkdir(pic_folder)\n",
    "    for (name, figures) in all_target_figures:\n",
    "        for idx, fig in enumerate(figures):\n",
    "            if fig != None:\n",
    "                fig.savefig(f'{pic_folder}/{idx}_{name}.png')\n",
    "                fig.savefig(f'{pic_folder}/{idx}_{name}.svg')\n",
    "    plt.close('all')\n",
    "\n",
    "    print(f\"Saved {x_test.shape[0] + x_train.shape[0]} values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
